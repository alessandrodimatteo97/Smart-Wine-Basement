{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd0d8c9e401e2a85200b96cf372039ed4aef0521768a8aba4f570fb90fdee80e932",
   "display_name": "Python 3.6.13 64-bit ('ML': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv(\"./Datasets/winequality-white.csv\", ';') \n",
    "columns = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides',\n",
    "          'free sulfur dioxide', 'total sulfur dioxide', 'density', 'ph', 'sulphates', 'alcohol', 'quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.0</td>\n      <td>0.27</td>\n      <td>0.36</td>\n      <td>20.7</td>\n      <td>0.045</td>\n      <td>45.0</td>\n      <td>170.0</td>\n      <td>1.00100</td>\n      <td>3.00</td>\n      <td>0.45</td>\n      <td>8.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.3</td>\n      <td>0.30</td>\n      <td>0.34</td>\n      <td>1.6</td>\n      <td>0.049</td>\n      <td>14.0</td>\n      <td>132.0</td>\n      <td>0.99400</td>\n      <td>3.30</td>\n      <td>0.49</td>\n      <td>9.5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.1</td>\n      <td>0.28</td>\n      <td>0.40</td>\n      <td>6.9</td>\n      <td>0.050</td>\n      <td>30.0</td>\n      <td>97.0</td>\n      <td>0.99510</td>\n      <td>3.26</td>\n      <td>0.44</td>\n      <td>10.1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.99560</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.2</td>\n      <td>0.23</td>\n      <td>0.32</td>\n      <td>8.5</td>\n      <td>0.058</td>\n      <td>47.0</td>\n      <td>186.0</td>\n      <td>0.99560</td>\n      <td>3.19</td>\n      <td>0.40</td>\n      <td>9.9</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4893</th>\n      <td>6.2</td>\n      <td>0.21</td>\n      <td>0.29</td>\n      <td>1.6</td>\n      <td>0.039</td>\n      <td>24.0</td>\n      <td>92.0</td>\n      <td>0.99114</td>\n      <td>3.27</td>\n      <td>0.50</td>\n      <td>11.2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4894</th>\n      <td>6.6</td>\n      <td>0.32</td>\n      <td>0.36</td>\n      <td>8.0</td>\n      <td>0.047</td>\n      <td>57.0</td>\n      <td>168.0</td>\n      <td>0.99490</td>\n      <td>3.15</td>\n      <td>0.46</td>\n      <td>9.6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4895</th>\n      <td>6.5</td>\n      <td>0.24</td>\n      <td>0.19</td>\n      <td>1.2</td>\n      <td>0.041</td>\n      <td>30.0</td>\n      <td>111.0</td>\n      <td>0.99254</td>\n      <td>2.99</td>\n      <td>0.46</td>\n      <td>9.4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4896</th>\n      <td>5.5</td>\n      <td>0.29</td>\n      <td>0.30</td>\n      <td>1.1</td>\n      <td>0.022</td>\n      <td>20.0</td>\n      <td>110.0</td>\n      <td>0.98869</td>\n      <td>3.34</td>\n      <td>0.38</td>\n      <td>12.8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4897</th>\n      <td>6.0</td>\n      <td>0.21</td>\n      <td>0.38</td>\n      <td>0.8</td>\n      <td>0.020</td>\n      <td>22.0</td>\n      <td>98.0</td>\n      <td>0.98941</td>\n      <td>3.26</td>\n      <td>0.32</td>\n      <td>11.8</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>4898 rows Ã— 12 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       count        mean        std      min         25%  \\\n",
       "fixed acidity         4898.0    6.854788   0.843868  3.80000    6.300000   \n",
       "volatile acidity      4898.0    0.278241   0.100795  0.08000    0.210000   \n",
       "citric acid           4898.0    0.334192   0.121020  0.00000    0.270000   \n",
       "residual sugar        4898.0    6.391415   5.072058  0.60000    1.700000   \n",
       "chlorides             4898.0    0.045772   0.021848  0.00900    0.036000   \n",
       "free sulfur dioxide   4898.0   35.308085  17.007137  2.00000   23.000000   \n",
       "total sulfur dioxide  4898.0  138.360657  42.498065  9.00000  108.000000   \n",
       "density               4898.0    0.994027   0.002991  0.98711    0.991723   \n",
       "pH                    4898.0    3.188267   0.151001  2.72000    3.090000   \n",
       "sulphates             4898.0    0.489847   0.114126  0.22000    0.410000   \n",
       "alcohol               4898.0   10.514267   1.230621  8.00000    9.500000   \n",
       "quality               4898.0    5.877909   0.885639  3.00000    5.000000   \n",
       "\n",
       "                            50%       75%        max  \n",
       "fixed acidity           6.80000    7.3000   14.20000  \n",
       "volatile acidity        0.26000    0.3200    1.10000  \n",
       "citric acid             0.32000    0.3900    1.66000  \n",
       "residual sugar          5.20000    9.9000   65.80000  \n",
       "chlorides               0.04300    0.0500    0.34600  \n",
       "free sulfur dioxide    34.00000   46.0000  289.00000  \n",
       "total sulfur dioxide  134.00000  167.0000  440.00000  \n",
       "density                 0.99374    0.9961    1.03898  \n",
       "pH                      3.18000    3.2800    3.82000  \n",
       "sulphates               0.47000    0.5500    1.08000  \n",
       "alcohol                10.40000   11.4000   14.20000  \n",
       "quality                 6.00000    6.0000    9.00000  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>fixed acidity</th>\n      <td>4898.0</td>\n      <td>6.854788</td>\n      <td>0.843868</td>\n      <td>3.80000</td>\n      <td>6.300000</td>\n      <td>6.80000</td>\n      <td>7.3000</td>\n      <td>14.20000</td>\n    </tr>\n    <tr>\n      <th>volatile acidity</th>\n      <td>4898.0</td>\n      <td>0.278241</td>\n      <td>0.100795</td>\n      <td>0.08000</td>\n      <td>0.210000</td>\n      <td>0.26000</td>\n      <td>0.3200</td>\n      <td>1.10000</td>\n    </tr>\n    <tr>\n      <th>citric acid</th>\n      <td>4898.0</td>\n      <td>0.334192</td>\n      <td>0.121020</td>\n      <td>0.00000</td>\n      <td>0.270000</td>\n      <td>0.32000</td>\n      <td>0.3900</td>\n      <td>1.66000</td>\n    </tr>\n    <tr>\n      <th>residual sugar</th>\n      <td>4898.0</td>\n      <td>6.391415</td>\n      <td>5.072058</td>\n      <td>0.60000</td>\n      <td>1.700000</td>\n      <td>5.20000</td>\n      <td>9.9000</td>\n      <td>65.80000</td>\n    </tr>\n    <tr>\n      <th>chlorides</th>\n      <td>4898.0</td>\n      <td>0.045772</td>\n      <td>0.021848</td>\n      <td>0.00900</td>\n      <td>0.036000</td>\n      <td>0.04300</td>\n      <td>0.0500</td>\n      <td>0.34600</td>\n    </tr>\n    <tr>\n      <th>free sulfur dioxide</th>\n      <td>4898.0</td>\n      <td>35.308085</td>\n      <td>17.007137</td>\n      <td>2.00000</td>\n      <td>23.000000</td>\n      <td>34.00000</td>\n      <td>46.0000</td>\n      <td>289.00000</td>\n    </tr>\n    <tr>\n      <th>total sulfur dioxide</th>\n      <td>4898.0</td>\n      <td>138.360657</td>\n      <td>42.498065</td>\n      <td>9.00000</td>\n      <td>108.000000</td>\n      <td>134.00000</td>\n      <td>167.0000</td>\n      <td>440.00000</td>\n    </tr>\n    <tr>\n      <th>density</th>\n      <td>4898.0</td>\n      <td>0.994027</td>\n      <td>0.002991</td>\n      <td>0.98711</td>\n      <td>0.991723</td>\n      <td>0.99374</td>\n      <td>0.9961</td>\n      <td>1.03898</td>\n    </tr>\n    <tr>\n      <th>pH</th>\n      <td>4898.0</td>\n      <td>3.188267</td>\n      <td>0.151001</td>\n      <td>2.72000</td>\n      <td>3.090000</td>\n      <td>3.18000</td>\n      <td>3.2800</td>\n      <td>3.82000</td>\n    </tr>\n    <tr>\n      <th>sulphates</th>\n      <td>4898.0</td>\n      <td>0.489847</td>\n      <td>0.114126</td>\n      <td>0.22000</td>\n      <td>0.410000</td>\n      <td>0.47000</td>\n      <td>0.5500</td>\n      <td>1.08000</td>\n    </tr>\n    <tr>\n      <th>alcohol</th>\n      <td>4898.0</td>\n      <td>10.514267</td>\n      <td>1.230621</td>\n      <td>8.00000</td>\n      <td>9.500000</td>\n      <td>10.40000</td>\n      <td>11.4000</td>\n      <td>14.20000</td>\n    </tr>\n    <tr>\n      <th>quality</th>\n      <td>4898.0</td>\n      <td>5.877909</td>\n      <td>0.885639</td>\n      <td>3.00000</td>\n      <td>5.000000</td>\n      <td>6.00000</td>\n      <td>6.0000</td>\n      <td>9.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if row['quality'] <= 5:\n",
    "        df.iloc[index, -1] = 0\n",
    "    elif row['quality'] >= 6 and row['quality'] <= 7:\n",
    "        df.iloc[index, -1] = 1\n",
    "    elif row['quality'] >= 8:\n",
    "        df.iloc[index, -1] = 2\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[198  96   1]\n [114 522  10]\n [  4  31   4]]\n              precision    recall  f1-score   support\n\n           0       0.63      0.67      0.65       295\n           1       0.80      0.81      0.81       646\n           2       0.27      0.10      0.15        39\n\n    accuracy                           0.74       980\n   macro avg       0.57      0.53      0.53       980\nweighted avg       0.73      0.74      0.73       980\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "392/392 [==============================] - 1s 794us/step - loss: 0.2931 - accuracy: 0.6272\n",
      "Epoch 2/100\n",
      "392/392 [==============================] - 0s 892us/step - loss: 0.2000 - accuracy: 0.7275\n",
      "Epoch 3/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7402\n",
      "Epoch 4/100\n",
      "392/392 [==============================] - 0s 910us/step - loss: 0.2014 - accuracy: 0.7298\n",
      "Epoch 5/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.7356\n",
      "Epoch 6/100\n",
      "392/392 [==============================] - 0s 925us/step - loss: 0.1755 - accuracy: 0.7647\n",
      "Epoch 7/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7355\n",
      "Epoch 8/100\n",
      "392/392 [==============================] - 0s 919us/step - loss: 0.1768 - accuracy: 0.7662\n",
      "Epoch 9/100\n",
      "392/392 [==============================] - 0s 825us/step - loss: 0.1681 - accuracy: 0.7625\n",
      "Epoch 10/100\n",
      "392/392 [==============================] - 0s 811us/step - loss: 0.1730 - accuracy: 0.7716\n",
      "Epoch 11/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1590 - accuracy: 0.7860\n",
      "Epoch 12/100\n",
      "392/392 [==============================] - 1s 1ms/step - loss: 0.1571 - accuracy: 0.7871\n",
      "Epoch 13/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1548 - accuracy: 0.7935\n",
      "Epoch 14/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.8003\n",
      "Epoch 15/100\n",
      "392/392 [==============================] - 0s 979us/step - loss: 0.1501 - accuracy: 0.7940\n",
      "Epoch 16/100\n",
      "392/392 [==============================] - 0s 899us/step - loss: 0.1531 - accuracy: 0.7906\n",
      "Epoch 17/100\n",
      "392/392 [==============================] - 0s 851us/step - loss: 0.1450 - accuracy: 0.8011\n",
      "Epoch 18/100\n",
      "392/392 [==============================] - 0s 924us/step - loss: 0.1329 - accuracy: 0.8211\n",
      "Epoch 19/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.8168\n",
      "Epoch 20/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.8189\n",
      "Epoch 21/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1294 - accuracy: 0.8230\n",
      "Epoch 22/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.8287\n",
      "Epoch 23/100\n",
      "392/392 [==============================] - 0s 985us/step - loss: 0.1271 - accuracy: 0.8305\n",
      "Epoch 24/100\n",
      "392/392 [==============================] - 0s 879us/step - loss: 0.1244 - accuracy: 0.8324\n",
      "Epoch 25/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.8304\n",
      "Epoch 26/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.8402\n",
      "Epoch 27/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.8514\n",
      "Epoch 28/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.8510\n",
      "Epoch 29/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.1065 - accuracy: 0.8527\n",
      "Epoch 30/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.8707\n",
      "Epoch 31/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.0978 - accuracy: 0.8664\n",
      "Epoch 32/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.8659\n",
      "Epoch 33/100\n",
      "392/392 [==============================] - 0s 1ms/step - loss: 0.0872 - accuracy: 0.8783\n",
      "Epoch 34/100\n",
      "392/392 [==============================] - 0s 718us/step - loss: 0.0950 - accuracy: 0.8625\n",
      "Epoch 35/100\n",
      "392/392 [==============================] - 0s 774us/step - loss: 0.0887 - accuracy: 0.8676\n",
      "Epoch 36/100\n",
      "392/392 [==============================] - 0s 856us/step - loss: 0.0861 - accuracy: 0.8835\n",
      "Epoch 37/100\n",
      "392/392 [==============================] - 0s 802us/step - loss: 0.0801 - accuracy: 0.8850\n",
      "Epoch 38/100\n",
      "392/392 [==============================] - 0s 860us/step - loss: 0.0808 - accuracy: 0.8796\n",
      "Epoch 39/100\n",
      "392/392 [==============================] - 0s 813us/step - loss: 0.0802 - accuracy: 0.8876\n",
      "Epoch 40/100\n",
      "392/392 [==============================] - 0s 780us/step - loss: 0.0792 - accuracy: 0.8868\n",
      "Epoch 41/100\n",
      "392/392 [==============================] - 0s 665us/step - loss: 0.0731 - accuracy: 0.8868\n",
      "Epoch 42/100\n",
      "392/392 [==============================] - 0s 845us/step - loss: 0.0710 - accuracy: 0.9051\n",
      "Epoch 43/100\n",
      "392/392 [==============================] - 0s 754us/step - loss: 0.0715 - accuracy: 0.8934\n",
      "Epoch 44/100\n",
      "392/392 [==============================] - 0s 905us/step - loss: 0.0689 - accuracy: 0.9006\n",
      "Epoch 45/100\n",
      "392/392 [==============================] - 0s 757us/step - loss: 0.0712 - accuracy: 0.8943\n",
      "Epoch 46/100\n",
      "392/392 [==============================] - 0s 735us/step - loss: 0.0683 - accuracy: 0.8992\n",
      "Epoch 47/100\n",
      "392/392 [==============================] - 0s 757us/step - loss: 0.0608 - accuracy: 0.9102\n",
      "Epoch 48/100\n",
      "392/392 [==============================] - 0s 830us/step - loss: 0.0631 - accuracy: 0.9116\n",
      "Epoch 49/100\n",
      "392/392 [==============================] - 0s 823us/step - loss: 0.0599 - accuracy: 0.9146\n",
      "Epoch 50/100\n",
      "392/392 [==============================] - 0s 869us/step - loss: 0.0601 - accuracy: 0.9074\n",
      "Epoch 51/100\n",
      "392/392 [==============================] - 0s 859us/step - loss: 0.0585 - accuracy: 0.9132\n",
      "Epoch 52/100\n",
      "392/392 [==============================] - 0s 893us/step - loss: 0.0529 - accuracy: 0.9215\n",
      "Epoch 53/100\n",
      "392/392 [==============================] - 0s 838us/step - loss: 0.0526 - accuracy: 0.9244\n",
      "Epoch 54/100\n",
      "392/392 [==============================] - 0s 787us/step - loss: 0.0560 - accuracy: 0.9214\n",
      "Epoch 55/100\n",
      "392/392 [==============================] - 0s 778us/step - loss: 0.0557 - accuracy: 0.9210\n",
      "Epoch 56/100\n",
      "392/392 [==============================] - 0s 796us/step - loss: 0.0485 - accuracy: 0.9303\n",
      "Epoch 57/100\n",
      "392/392 [==============================] - 0s 797us/step - loss: 0.0524 - accuracy: 0.9215\n",
      "Epoch 58/100\n",
      "392/392 [==============================] - 0s 787us/step - loss: 0.0514 - accuracy: 0.9198\n",
      "Epoch 59/100\n",
      "392/392 [==============================] - 0s 798us/step - loss: 0.0461 - accuracy: 0.9293\n",
      "Epoch 60/100\n",
      "392/392 [==============================] - 0s 812us/step - loss: 0.0492 - accuracy: 0.9269\n",
      "Epoch 61/100\n",
      "392/392 [==============================] - 0s 787us/step - loss: 0.0454 - accuracy: 0.9380\n",
      "Epoch 62/100\n",
      "392/392 [==============================] - 0s 806us/step - loss: 0.0457 - accuracy: 0.9343\n",
      "Epoch 63/100\n",
      "392/392 [==============================] - 0s 808us/step - loss: 0.0405 - accuracy: 0.9379\n",
      "Epoch 64/100\n",
      "392/392 [==============================] - 0s 769us/step - loss: 0.0397 - accuracy: 0.9402\n",
      "Epoch 65/100\n",
      "392/392 [==============================] - 0s 755us/step - loss: 0.0435 - accuracy: 0.9323\n",
      "Epoch 66/100\n",
      "392/392 [==============================] - 0s 792us/step - loss: 0.0479 - accuracy: 0.9330\n",
      "Epoch 67/100\n",
      "392/392 [==============================] - 0s 842us/step - loss: 0.0443 - accuracy: 0.9342\n",
      "Epoch 68/100\n",
      "392/392 [==============================] - 0s 823us/step - loss: 0.0387 - accuracy: 0.9417\n",
      "Epoch 69/100\n",
      "392/392 [==============================] - 0s 842us/step - loss: 0.0397 - accuracy: 0.9348\n",
      "Epoch 70/100\n",
      "392/392 [==============================] - 0s 802us/step - loss: 0.0360 - accuracy: 0.9398\n",
      "Epoch 71/100\n",
      "392/392 [==============================] - 0s 800us/step - loss: 0.0355 - accuracy: 0.9463\n",
      "Epoch 72/100\n",
      "392/392 [==============================] - 0s 851us/step - loss: 0.0371 - accuracy: 0.9328\n",
      "Epoch 73/100\n",
      "392/392 [==============================] - 0s 809us/step - loss: 0.0356 - accuracy: 0.9409\n",
      "Epoch 74/100\n",
      "392/392 [==============================] - 0s 813us/step - loss: 0.0355 - accuracy: 0.9402\n",
      "Epoch 75/100\n",
      "392/392 [==============================] - 0s 745us/step - loss: 0.0388 - accuracy: 0.9379\n",
      "Epoch 76/100\n",
      "392/392 [==============================] - 0s 797us/step - loss: 0.0388 - accuracy: 0.9392\n",
      "Epoch 77/100\n",
      "392/392 [==============================] - 0s 777us/step - loss: 0.0356 - accuracy: 0.9376\n",
      "Epoch 78/100\n",
      "392/392 [==============================] - 0s 779us/step - loss: 0.0318 - accuracy: 0.9471\n",
      "Epoch 79/100\n",
      "392/392 [==============================] - 0s 823us/step - loss: 0.0342 - accuracy: 0.9360\n",
      "Epoch 80/100\n",
      "392/392 [==============================] - 0s 779us/step - loss: 0.0344 - accuracy: 0.9406\n",
      "Epoch 81/100\n",
      "392/392 [==============================] - 0s 762us/step - loss: 0.0386 - accuracy: 0.9346\n",
      "Epoch 82/100\n",
      "392/392 [==============================] - 0s 717us/step - loss: 0.0318 - accuracy: 0.9516\n",
      "Epoch 83/100\n",
      "392/392 [==============================] - 0s 748us/step - loss: 0.0339 - accuracy: 0.9516\n",
      "Epoch 84/100\n",
      "392/392 [==============================] - 0s 795us/step - loss: 0.0322 - accuracy: 0.9420\n",
      "Epoch 85/100\n",
      "392/392 [==============================] - 0s 747us/step - loss: 0.0318 - accuracy: 0.9421\n",
      "Epoch 86/100\n",
      "392/392 [==============================] - 0s 773us/step - loss: 0.0295 - accuracy: 0.9462\n",
      "Epoch 87/100\n",
      "392/392 [==============================] - 0s 745us/step - loss: 0.0323 - accuracy: 0.9420\n",
      "Epoch 88/100\n",
      "392/392 [==============================] - 0s 758us/step - loss: 0.0310 - accuracy: 0.9413\n",
      "Epoch 89/100\n",
      "392/392 [==============================] - 0s 748us/step - loss: 0.0298 - accuracy: 0.9476\n",
      "Epoch 90/100\n",
      "392/392 [==============================] - 0s 724us/step - loss: 0.0308 - accuracy: 0.9420\n",
      "Epoch 91/100\n",
      "392/392 [==============================] - 0s 766us/step - loss: 0.0337 - accuracy: 0.9450\n",
      "Epoch 92/100\n",
      "392/392 [==============================] - 0s 769us/step - loss: 0.0265 - accuracy: 0.9480\n",
      "Epoch 93/100\n",
      "392/392 [==============================] - 0s 741us/step - loss: 0.0291 - accuracy: 0.9478\n",
      "Epoch 94/100\n",
      "392/392 [==============================] - 0s 939us/step - loss: 0.0272 - accuracy: 0.9539\n",
      "Epoch 95/100\n",
      "392/392 [==============================] - 0s 935us/step - loss: 0.0278 - accuracy: 0.9522\n",
      "Epoch 96/100\n",
      "392/392 [==============================] - 0s 981us/step - loss: 0.0260 - accuracy: 0.9494\n",
      "Epoch 97/100\n",
      "392/392 [==============================] - 0s 935us/step - loss: 0.0254 - accuracy: 0.9545\n",
      "Epoch 98/100\n",
      "392/392 [==============================] - 0s 952us/step - loss: 0.0290 - accuracy: 0.9530\n",
      "Epoch 99/100\n",
      "392/392 [==============================] - 0s 936us/step - loss: 0.0277 - accuracy: 0.9456\n",
      "Epoch 100/100\n",
      "392/392 [==============================] - 0s 837us/step - loss: 0.0259 - accuracy: 0.9537\n",
      "31/31 [==============================] - 0s 703us/step - loss: 0.2322 - accuracy: 0.7633\n",
      "Test results - Loss: 0.23221692442893982 - Accuracy: 0.7632653117179871%\n"
     ]
    }
   ],
   "source": [
    "### MLP Perceptron\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(11,), activation='relu'))\n",
    "model.add(Dense(12*12, activation='relu'))\n",
    "model.add(Dense(12*12, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Configure the model and start training\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=10, verbose=1)\n",
    "\n",
    "# Test the model after training\n",
    "test_results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.68      0.75      0.71       295\n           1       0.85      0.81      0.83       646\n           2       0.33      0.36      0.35        39\n\n    accuracy                           0.77       980\n   macro avg       0.62      0.64      0.63       980\nweighted avg       0.78      0.77      0.77       980\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_pred6 = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.76      0.73      0.74       295\n           1       0.85      0.90      0.87       646\n           2       0.85      0.28      0.42        39\n\n    accuracy                           0.82       980\n   macro avg       0.82      0.63      0.68       980\nweighted avg       0.82      0.82      0.81       980\n\n"
     ]
    }
   ],
   "source": [
    "# Best choice Random Forest\n",
    "classifier = RandomForestClassifier(random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['classifier/whiteClassifier.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "### Creation of a ML model\n",
    "from joblib import dump, load\n",
    "classifier = RandomForestClassifier(random_state=0)\n",
    "classifier.fit(X, y)\n",
    "\n",
    "dump(classifier, 'classifier/whiteClassifier.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}